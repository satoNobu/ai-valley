# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ:
# dataset/
# â”œâ”€â”€ spike/
# â”‚   â”œâ”€â”€ 1/ï¼ˆâ† ãƒ•ã‚¡ã‚¤ãƒ«åè‡ªç”±ã§OKï¼‰
# â”‚   â”‚   â”œâ”€â”€ frame_0190.jpg
# â”‚   â”‚   â”œâ”€â”€ frame_0191.jpg
# â”‚   â””â”€â”€ 2/
# â”œâ”€â”€ receive/
# â””â”€â”€ block/

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ:
# dataset/
# â”œâ”€â”€ spike/
# â”œâ”€â”€ receive/
# â”œâ”€â”€ block/
# â”œâ”€â”€ none/
# â””â”€â”€ serve/

# confusion_matrix.py - æ­£ä¾‹ vs ä»–ã™ã¹ã¦ï¼ˆãƒãƒ«ãƒè² ä¾‹ï¼‰å¯¾å¿œç‰ˆ

import os
import glob
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Masking
from tensorflow.keras.preprocessing.image import img_to_array, load_img

# å…±é€šè¨­å®š
IMG_SIZE = (64, 64)
MAX_FRAMES = 20
DATASET_DIR = 'dataset'
MODEL_SAVE_DIR = '/shared'
TARGET_CLASSES = ['spike', 'block', 'receive', 'serve']

# ãƒ¢ãƒ‡ãƒ«ä½œæˆé–¢æ•°
def create_model(output_classes):
    model = Sequential([
        TimeDistributed(Conv2D(16, (3, 3), activation='relu'), input_shape=(MAX_FRAMES, *IMG_SIZE, 3)),
        TimeDistributed(MaxPooling2D((2, 2))),
        TimeDistributed(Flatten()),
        Masking(mask_value=0.0),
        LSTM(32),
        Dense(output_classes, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# clipèª­ã¿è¾¼ã¿
def load_clip(folder_path):
    frame_paths = sorted(glob.glob(os.path.join(folder_path, "*.jpg")))
    frames = []
    for path in frame_paths[:MAX_FRAMES]:
        img = load_img(path, target_size=IMG_SIZE)
        arr = img_to_array(img) / 255.0
        frames.append(arr)
    if not frames:
        return None
    pad_frame = np.zeros_like(frames[0])
    while len(frames) < MAX_FRAMES:
        frames.append(pad_frame)
    return np.stack(frames, axis=0)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ï¼ˆæ­£ä¾‹ vs ä»–ã™ã¹ã¦ï¼‰
def load_dataset_for_class(target_class):
    clips = []
    labels = []
    all_classes = os.listdir(DATASET_DIR)
    for label in all_classes:
        label_dir = os.path.join(DATASET_DIR, label)
        if not os.path.isdir(label_dir):
            continue
        for clip_name in os.listdir(label_dir):
            clip_path = os.path.join(label_dir, clip_name)
            clip = load_clip(clip_path)
            if clip is not None:
                label_val = 1 if label == target_class else 0
                clips.append(clip)
                labels.append(label_val)
    return np.array(clips), tf.keras.utils.to_categorical(labels, num_classes=2)

# å„ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨ä¿å­˜
for action in TARGET_CLASSES:
    print(f"\nğŸ§  ãƒ¢ãƒ‡ãƒ«: {action} vs all others")
    X, y = load_dataset_for_class(action)
    model_path = os.path.join(MODEL_SAVE_DIR, f"{action}_model.h5")

    if os.path.exists(model_path):
        model = load_model(model_path)
        print(f"âœ… {action}_model èª­ã¿è¾¼ã¿æ¸ˆ")
    else:
        model = create_model(2)
        print(f"ğŸ†• {action}_model æ–°è¦ä½œæˆ")

    model.fit(X, y, epochs=10, batch_size=4)
    model.save(model_path)
    print(f"ğŸ’¾ {action}_model ä¿å­˜æ¸ˆ â†’ {model_path}")