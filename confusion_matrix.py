# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ:
# dataset/
# â”œâ”€â”€ spike/
# â”‚   â”œâ”€â”€ 1/ï¼ˆâ† ãƒ•ã‚¡ã‚¤ãƒ«åè‡ªç”±ã§OKï¼‰
# â”‚   â”‚   â”œâ”€â”€ frame_0190.jpg
# â”‚   â”‚   â”œâ”€â”€ frame_0191.jpg
# â”‚   â””â”€â”€ 2/
# â”œâ”€â”€ receive/
# â””â”€â”€ block/

import os
import glob
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Masking
from tensorflow.keras.preprocessing.image import img_to_array, load_img

# èª­ã¿è¾¼ã¿è¨­å®š
IMG_SIZE = (64, 64)
MAX_FRAMES = 20
CLASSES = ['spike', 'receive', 'block']
DATASET_DIR = 'dataset'
MODEL_PATH = '/shared/spike_action_model_lstm.h5'

# ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ä»˜ãã®clipèª­ã¿è¾¼ã¿ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ åè‡ªç”±å¯¾å¿œï¼‰
def load_clip(folder_path):
    frame_paths = sorted(glob.glob(os.path.join(folder_path, "*.jpg")))
    frames = []
    for path in frame_paths[:MAX_FRAMES]:
        img = load_img(path, target_size=IMG_SIZE)
        arr = img_to_array(img) / 255.0
        frames.append(arr)
    if not frames:
        return None
    pad_frame = np.zeros_like(frames[0])
    while len(frames) < MAX_FRAMES:
        frames.append(pad_frame)
    return np.stack(frames, axis=0)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
def load_dataset():
    clips = []
    labels = []
    for label_idx, label in enumerate(CLASSES):
        label_dir = os.path.join(DATASET_DIR, label)
        for clip_name in os.listdir(label_dir):
            clip_path = os.path.join(label_dir, clip_name)
            clip = load_clip(clip_path)
            if clip is not None:
                clips.append(clip)
                labels.append(label_idx)
    return np.array(clips), tf.keras.utils.to_categorical(labels, num_classes=len(CLASSES))

X, y = load_dataset()  # shape: (N, MAX_FRAMES, 64, 64, 3)

# æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Œã°èª­ã¿è¾¼ã‚€ã€ãªã‘ã‚Œã°æ–°è¦ä½œæˆ
if os.path.exists(MODEL_PATH):
    model = load_model(MODEL_PATH)
    print("âœ… æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # è¿½å­¦ç¿’å¯èƒ½ã«ã™ã‚‹ãŸã‚å†ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
else:
    model = Sequential([
        TimeDistributed(Conv2D(16, (3, 3), activation='relu'), input_shape=(MAX_FRAMES, *IMG_SIZE, 3)),
        TimeDistributed(MaxPooling2D((2, 2))),
        TimeDistributed(Flatten()),
        Masking(mask_value=0.0),
        LSTM(32),
        Dense(len(CLASSES), activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    print("ğŸ†• æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ")

# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆç©ã¿é‡ã­å‹ï¼‰
model.fit(X, y, epochs=10, batch_size=4)

# ãƒ¢ãƒ‡ãƒ«ä¿å­˜ï¼ˆå¤–éƒ¨å…±æœ‰ãƒ•ã‚©ãƒ«ãƒ€ã«å‡ºåŠ›ï¼‰
model.save(MODEL_PATH)
print("ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼š", MODEL_PATH)